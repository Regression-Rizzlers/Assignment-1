{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.multioutput import MultiOutputRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    A = np.loadtxt(file_path)\n",
    "    X = A[:, :9]    # Input features\n",
    "    y = A[:, 9:]    # Output labels\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all 3 datasets\n",
    "X_final, y_final = load_data('data/tictac_final.txt')\n",
    "y_final = y_final[:, 0]\n",
    "\n",
    "X_single, y_single = load_data('data/tictac_single.txt')\n",
    "y_single = y_single[:, 0]\n",
    "\n",
    "X_multi, y_multi = load_data('data/tictac_multi.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_clf_parameters(X_train, y_train):\n",
    "    model = KNeighborsClassifier()\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {'n_neighbors': np.arange(1, 10),\n",
    "                  'weights': ['uniform', 'distance'],\n",
    "                  'metric': ['minkowski', 'euclidean']}\n",
    "\n",
    "    # RandomizedSearchCV to find the best parameters\n",
    "    randomized_search = RandomizedSearchCV(model, param_distributions=param_grid, n_iter=10, cv=10, random_state=42)\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_params = randomized_search.best_params_\n",
    "    print(best_params)\n",
    "        \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_clf_train(X, y, is_one_tenth = False):\n",
    "    # Split into training and testing data\n",
    "    if is_one_tenth == False:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "    # Find the best parameters\n",
    "    best_params = finetune_clf_parameters(X_train, y_train)\n",
    "\n",
    "    # Define and train model\n",
    "    model = KNeighborsClassifier(**best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get cross validation accuracy\n",
    "    val_accuracy = cross_val_score(model, X_train, y_train, cv=10, scoring=\"accuracy\")\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    # Get test accuracy\n",
    "    y_pred = model.predict(X_test)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Get confusion matrix\n",
    "    confusion_mtrx = confusion_matrix(y_test, y_pred, normalize=\"true\")\n",
    "\n",
    "    return val_accuracy, test_accuracy, confusion_mtrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_clf_results(val_accuracy, test_accuracy, confusion_mtrx, dataset_name):\n",
    "    print(f\"Performance of KNN Classification on {dataset_name}:\")\n",
    "    print(\"Cross Validation Accuracy = \", val_accuracy)\n",
    "    print(\"Test Accuracy = \", test_accuracy)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mtrx.round(decimals=3)) # Round to 3 decimal places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'distance', 'n_neighbors': 2, 'metric': 'euclidean'}\n",
      "Performance of KNN Classification on Final Dataset:\n",
      "Cross Validation Accuracy =  1.0\n",
      "Test Accuracy =  1.0\n",
      "Confusion Matrix:\n",
      "[[1. 0.]\n",
      " [0. 1.]]\n",
      "Extra Credit #2 - Train the models on 1/10th of the data\n",
      "{'weights': 'distance', 'n_neighbors': 2, 'metric': 'euclidean'}\n",
      "Performance of KNN Classification on Final Dataset:\n",
      "Cross Validation Accuracy =  0.861111111111111\n",
      "Test Accuracy =  0.8864426419466975\n",
      "Confusion Matrix:\n",
      "[[0.78  0.22 ]\n",
      " [0.055 0.945]]\n"
     ]
    }
   ],
   "source": [
    "val_acc_final, test_acc_final, confusion_mtrx_final = knn_clf_train(X_final, y_final)\n",
    "print_clf_results(val_acc_final, test_acc_final, confusion_mtrx_final, \"Final Dataset\")\n",
    "\n",
    "print(\"Extra Credit #2 - Train the models on 1/10th of the data\")\n",
    "val_acc_final, test_acc_final, confusion_mtrx_final = knn_clf_train(X_final, y_final, True)\n",
    "print_clf_results(val_acc_final, test_acc_final, confusion_mtrx_final, \"Final Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': 'distance', 'n_neighbors': 9, 'metric': 'euclidean'}\n",
      "Performance of KNN Classification on Single Dataset:\n",
      "Cross Validation Accuracy =  0.8715648854961833\n",
      "Test Accuracy =  0.9061784897025171\n",
      "Confusion Matrix:\n",
      "[[0.95  0.003 0.006 0.    0.031 0.    0.006 0.    0.003]\n",
      " [0.006 0.881 0.018 0.018 0.03  0.    0.012 0.006 0.03 ]\n",
      " [0.043 0.005 0.909 0.021 0.005 0.    0.011 0.005 0.   ]\n",
      " [0.009 0.026 0.026 0.889 0.017 0.    0.    0.    0.034]\n",
      " [0.04  0.01  0.    0.    0.95  0.    0.    0.    0.   ]\n",
      " [0.026 0.079 0.013 0.026 0.    0.855 0.    0.    0.   ]\n",
      " [0.03  0.    0.04  0.01  0.01  0.    0.909 0.    0.   ]\n",
      " [0.    0.12  0.    0.04  0.02  0.04  0.02  0.76  0.   ]\n",
      " [0.09  0.034 0.011 0.011 0.    0.    0.    0.022 0.831]]\n",
      "Extra Credit #2 - Train the models on 1/10th of the data\n",
      "{'weights': 'distance', 'n_neighbors': 9, 'metric': 'euclidean'}\n",
      "Performance of KNN Classification on Single Dataset:\n",
      "Cross Validation Accuracy =  0.6014918414918414\n",
      "Test Accuracy =  0.5980325644504749\n",
      "Confusion Matrix:\n",
      "[[0.809 0.046 0.041 0.003 0.041 0.004 0.026 0.018 0.012]\n",
      " [0.09  0.647 0.081 0.013 0.065 0.013 0.027 0.025 0.038]\n",
      " [0.157 0.095 0.581 0.024 0.061 0.003 0.027 0.015 0.037]\n",
      " [0.163 0.094 0.073 0.368 0.116 0.011 0.118 0.026 0.032]\n",
      " [0.153 0.116 0.046 0.028 0.569 0.012 0.029 0.022 0.025]\n",
      " [0.178 0.09  0.097 0.072 0.037 0.396 0.044 0.034 0.053]\n",
      " [0.184 0.064 0.099 0.054 0.045 0.004 0.493 0.016 0.041]\n",
      " [0.124 0.101 0.06  0.032 0.037 0.005 0.083 0.509 0.05 ]\n",
      " [0.219 0.068 0.078 0.024 0.078 0.007 0.019 0.027 0.479]]\n"
     ]
    }
   ],
   "source": [
    "val_acc_single, test_acc_single, confusion_mtrx_single = knn_clf_train(X_single, y_single)\n",
    "print_clf_results(val_acc_single, test_acc_single, confusion_mtrx_single, \"Single Dataset\")\n",
    "\n",
    "print(\"Extra Credit #2 - Train the models on 1/10th of the data\")\n",
    "val_acc_single, test_acc_single, confusion_mtrx_single = knn_clf_train(X_single, y_single, True)\n",
    "print_clf_results(val_acc_single, test_acc_single, confusion_mtrx_single, \"Single Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_reg_parameters(X_train, y_train):\n",
    "    knn_regressor = KNeighborsRegressor()\n",
    "    multioutput_regressor = MultiOutputRegressor(knn_regressor)\n",
    "\n",
    "    # Define the parameter grid\n",
    "    param_grid = {'estimator__n_neighbors': np.arange(1, 10),\n",
    "                  'estimator__weights': ['uniform', 'distance'],\n",
    "                  'estimator__metric': ['minkowski', 'euclidean']}\n",
    "\n",
    "    # RandomizedSearchCV to find the best value of k\n",
    "    randomized_search = RandomizedSearchCV(multioutput_regressor, param_grid, n_iter=10, cv=10, scoring='neg_mean_squared_error')\n",
    "    randomized_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best value of k\n",
    "    best_params = randomized_search.best_params_\n",
    "    print(best_params)\n",
    "        \n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_reg_train(X, y, is_one_tenth = False):\n",
    "    # Split into training and testing data\n",
    "    if is_one_tenth == False:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.1, shuffle=True, random_state=42)\n",
    "\n",
    "    # Find the best parameters\n",
    "    best_params = finetune_reg_parameters(X_train, y_train)\n",
    "\n",
    "    # Remove estimator__ in front of every hyperparameter\n",
    "    remove_str = \"estimator__\"\n",
    "    \n",
    "    for param in list(best_params.keys()):\n",
    "        if remove_str in param:\n",
    "            new_param = param.replace(remove_str, \"\")\n",
    "            best_params[new_param] = best_params[param]\n",
    "            del best_params[param]\n",
    "\n",
    "    # Define and train model\n",
    "    base_regressor = KNeighborsRegressor(**best_params)\n",
    "    model = MultiOutputRegressor(base_regressor)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Get cross validation accuracy\n",
    "    val_rmse = cross_val_score(model, X_train, y_train, cv=10, scoring=\"neg_mean_squared_error\")\n",
    "    val_rmse = np.mean(val_rmse * -1)  # Convert to positive\n",
    "\n",
    "    # Get test accuracy\n",
    "    test_accuracy = model.score(X_test, y_test)\n",
    "\n",
    "    # Get RMSE\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "\n",
    "    return val_rmse, test_accuracy, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_reg_results(val_rmse, test_accuracy, rmse, dataset_name):\n",
    "    print(f\"Performance of KNN Regression on {dataset_name}:\")\n",
    "    print(\"Cross Validation RMSE = \", val_rmse)\n",
    "    print(\"Test Accuracy = \", test_accuracy)\n",
    "    print(\"RMSE = \", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'estimator__weights': 'distance', 'estimator__n_neighbors': 9, 'estimator__metric': 'minkowski'}\n",
      "Performance of KNN Regression on Multi Dataset:\n",
      "Cross Validation RMSE =  0.03542710084410962\n",
      "Test Accuracy =  0.829980034205453\n",
      "RMSE =  0.16690767106061566\n",
      "Extra Credit #2 - Train the models on 1/10th of the data\n",
      "{'estimator__weights': 'distance', 'estimator__n_neighbors': 9, 'estimator__metric': 'euclidean'}\n",
      "Performance of KNN Regression on Multi Dataset:\n",
      "Cross Validation RMSE =  0.10097217976779074\n",
      "Test Accuracy =  0.40517672391156345\n",
      "RMSE =  0.314836435944949\n"
     ]
    }
   ],
   "source": [
    "val_rmse_multi, test_acc_multi, rmse_multi = knn_reg_train(X_multi, y_multi)\n",
    "print_reg_results(val_rmse_multi, test_acc_multi, rmse_multi, \"Multi Dataset\")\n",
    "\n",
    "print(\"Extra Credit #2 - Train the models on 1/10th of the data\")\n",
    "val_rmse_multi, test_acc_multi, rmse_multi = knn_reg_train(X_multi, y_multi, True)\n",
    "print_reg_results(val_rmse_multi, test_acc_multi, rmse_multi, \"Multi Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
